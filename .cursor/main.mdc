---
alwaysApply: true
---
This repository **TODO**.
Our goal is a codebase that is **easy to read, navigate, reason about, diagnose, maintain and scale**. Follow the practices below to keep the codebase clear.

---
## 1. Coding Standards

### Logging

- Always use **lazy logging**, e.g.:
    
    ```python
    logger.info("Received response: %s", response)
    ```
    
    Never use f-strings or `%` for formatting inside logging calls.
    
- Your logs should clearly reconstruct the graph execution path for debugging.
    
- Use log levels appropriately:
    
    - `debug`: detailed internal state
    - `info`: high-level control flow
    - `warning`, `error`, `critical`: unexpected failures or critical issues

### Docstrings

- Use **Google-style** format for all public methods, functions, and classes.
    
- Example:
    
    ```python
    def fetch_tool_description(tool_id: str) -> ToolDescription:
        """Fetch metadata for a given tool from the MCP registry.
    
        Args:
            tool_id (str): Unique identifier of the tool.
    
        Returns:
            ToolDescription: Parsed metadata object.
        """
    ```
    
- Include all arguments, return types, exceptions (if any), and high-level descriptions.
    

### Type Hints

- Use full type annotations.
- Use **native Python types** (introduced in Python 3.9+) — e.g., use `list[str]` instead of `typing.List[str]`, `dict[str, Any]` instead of `Dict`.
- Use `Literal[...]` for variables or parameters with constrained options.

### Code Structure

- Structure code to be modular, composable, readable, scalable and testable.
- Prefer pure functions where possible.
- Keep I/O and side effects behind well-defined service layers.
- Extract helpers after the third repetition ("rule of three").
- Follow Python best practices (PEP8, black-compatible formatting).
- Avoid over-engineering: if splitting introduces **verbosity, indirection, or redundant abstractions**, reconsider. Our goal is **scalable, readable architecture** — not cargo-cult "best practices."

---

## 2. Configuration Management

### Single Source of Truth

- Use **one main config file** (`config.yaml`) in the project root as the single source of truth for all configurations.
- **Add new sections** to the existing config instead of creating separate config files.

### Config Structure

```yaml
# config.yaml - единый конфиг проекта
database:
  clickhouse:
    host: "localhost"
    port: 9000
    database: "analytics"
    user: "${CLICKHOUSE_USER}"
    password: "${CLICKHOUSE_PASSWORD}"
  postgres:
    host: "localhost" 
    port: 5432
    database: "reviews"
    user: "${POSTGRES_USER}"
    password: "${POSTGRES_PASSWORD}"

paths:
  base_output: "/data/artifacts"
  logs: "logs"
  temp: "/tmp/processing"

# Script-specific configurations
load_reviews_script:
  batch_size_branches: 10000
  total_batches: 1000
  region_id: 1
  reviews_days_old: 120
  batch_size_reviews: 100

ranking_script:
  model_name: "gpt-4"
  batch_size: 50
  max_tokens: 1000
  temperature: 0.7

llm_processing_script:
  prompt_template_path: "templates/analysis.txt"
  output_format: "json"
  retry_attempts: 3
```

### Using Configuration in Scripts

```python
from pydantic import BaseModel, Field
import yaml

from conf import CFG

class ScriptConfig(BaseModel):
    """Configuration for the specific script"""
    batch_size_branches: int = Field(description="Batch size for branches")
    total_batches: int = Field(description="Number of batches to process")
    region_id: int = Field(description="Region ID for filtering")


# Usage in main function
def run_main_function():
    script_config = ScriptConfig(**CFG.script)
    db_config = load_db_config()  # Load shared database config
    
    logger.info("Starting with batch_size=%d, region_id=%d", 
                config.batch_size_branches, config.region_id)
```

### Environment Variables

- Use environment variables for sensitive data (passwords, API keys).
- Reference them in config with `${env:VAR_NAME}` syntax.
- Provide defaults for non-sensitive configurations.

---

## 3. Dependency Management

- Use **[uv](https://github.com/astral-sh/uv)** exclusively (`uv pip install -r requirements.txt`, `uv venv .venv`, etc.).

---

## 4. Update Actions

Always keep **docs/status.md** up to date. It is a single source of truth for the project status and progress. It should briefly describe the current state of the project and also describe changes done in each iteration.

## 5. End-to-end Testing

**Include Test Snippets in Your Output**

- After the "Summary of Changes" in your PR description (or in the comment that delivers the code), add **concise code snippets** that:
    - Instantiate the agent or node.
    - Feed it minimal, representative inputs.
    - Print or log the results.
- **Describe the Expected Result**. For every snippet, state what the correct output or observable side-effect should be. Keep it short—one sentence per snippet is enough.
- Cover happy-path and one edge-case.
- Do **not** create a separate `tests/` module for these examples. Exhaustive unit tests still belong in tests/, but these end-to-end examples are for quick validation.

To run scripts, you will probably need to export:
```bash
source .venv/bin/activate # if venv was not activated before
export PYTHONPATH=$PYTHONPATH:${PWD}/src
python src/script.py
```

---

## 6. When in Doubt…

1. **Prefer explicitness** over hidden magic.
2. **Fail early**—raise, don't silently repair.
3. **Write the log you wish you'd had** when debugging at 3 AM.
4. **Add to existing config** instead of creating new config files.

---

Happy hacking — may your graphs be acyclic and your logs enlightening.